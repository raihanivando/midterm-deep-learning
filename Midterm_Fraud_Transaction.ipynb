{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7T2cQNlOQb0G+XIxR9vwm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihanivando/midterm-deep-learning/blob/main/Midterm_Fraud_Transaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJBcbNJU9yfq",
        "outputId": "eb4ef084-ab03-43b5-c13e-382b517a25fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7 test_transaction.csv\n",
            "Processing file 1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_ train_transaction.csv\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7\n",
            "From (redirected): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7&confirm=t&uuid=30485f8b-8ba4-433c-997b-93cff4d0c531\n",
            "To: /content/midterm_folder/test_transaction.csv\n",
            "100% 613M/613M [00:08<00:00, 69.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_\n",
            "From (redirected): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_&confirm=t&uuid=da532b76-d3ec-4cea-96c4-5d03fdc9df54\n",
            "To: /content/midterm_folder/train_transaction.csv\n",
            "100% 683M/683M [00:07<00:00, 89.4MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "#import gdown\n",
        "# kalian download semua file dari gdrive dibawah lalu buat folder (ex. midterm_folder)\n",
        "#https://drive.google.com/file/d/1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_/view?usp=sharing\n",
        "!gdown --folder 13855F-3guh83abqSUm_ffmrQcb5-5TUM -O midterm_folder\n",
        "#https://drive.google.com/drive/folders/13855F-3guh83abqSUm_ffmrQcb5-5TUM?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94c46c3e",
        "outputId": "bc27d0b2-f785-4b4e-8ad2-98f52b4ac50a"
      },
      "source": [
        "import gdown\n",
        "\n",
        "# Example: Downloading only 'train_transaction.csv'\n",
        "# The file ID for train_transaction.csv is 1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_\n",
        "!gdown --id 1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_ -O midterm_folder/train_transaction.csv\n",
        "\n",
        "# To download 'test_transaction.csv' instead, you would use its ID:\n",
        "!gdown --id 1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7 -O midterm_folder/test_transaction.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_\n",
            "From (redirected): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_&confirm=t&uuid=bd2ffa5a-cca9-4112-81b1-114434164cc0\n",
            "To: /content/midterm_folder/train_transaction.csv\n",
            "100% 683M/683M [00:05<00:00, 129MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7\n",
            "From (redirected): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7&confirm=t&uuid=1ea7de24-6122-497c-b5ff-61ced7004709\n",
            "To: /content/midterm_folder/test_transaction.csv\n",
            "100% 613M/613M [00:04<00:00, 138MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "BASE_PATH = \"midterm_folder\"\n",
        "\n",
        "train_transaction = pl.read_csv(f\"{BASE_PATH}/train_transaction.csv\")\n",
        "test_transaction  = pl.read_csv(f\"{BASE_PATH}/test_transaction.csv\")\n",
        "\n",
        "print(train_transaction.shape) #590540 row dan 393 feature + 1 target\n",
        "print(test_transaction.shape) #506691 row dan 393 feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGSd4rUxlIXp",
        "outputId": "7ed7a52d-5d02-4233-fb7c-33d54f7051ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(590540, 394)\n",
            "(506691, 393)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transaction.head() #isFraud adalah target featurenya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "II2nwLtU6iKx",
        "outputId": "36808d49-2cba-41bf-8910-252dfbea2905"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 394)\n",
              "┌───────────────┬─────────┬───────────────┬────────────────┬───┬──────┬──────┬──────┬──────┐\n",
              "│ TransactionID ┆ isFraud ┆ TransactionDT ┆ TransactionAmt ┆ … ┆ V336 ┆ V337 ┆ V338 ┆ V339 │\n",
              "│ ---           ┆ ---     ┆ ---           ┆ ---            ┆   ┆ ---  ┆ ---  ┆ ---  ┆ ---  │\n",
              "│ i64           ┆ i64     ┆ i64           ┆ f64            ┆   ┆ f64  ┆ f64  ┆ f64  ┆ f64  │\n",
              "╞═══════════════╪═════════╪═══════════════╪════════════════╪═══╪══════╪══════╪══════╪══════╡\n",
              "│ 2987000       ┆ 0       ┆ 86400         ┆ 68.5           ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 2987001       ┆ 0       ┆ 86401         ┆ 29.0           ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 2987002       ┆ 0       ┆ 86469         ┆ 59.0           ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 2987003       ┆ 0       ┆ 86499         ┆ 50.0           ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 2987004       ┆ 0       ┆ 86506         ┆ 50.0           ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0  ┆ 0.0  │\n",
              "└───────────────┴─────────┴───────────────┴────────────────┴───┴──────┴──────┴──────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 394)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>TransactionID</th><th>isFraud</th><th>TransactionDT</th><th>TransactionAmt</th><th>ProductCD</th><th>card1</th><th>card2</th><th>card3</th><th>card4</th><th>card5</th><th>card6</th><th>addr1</th><th>addr2</th><th>dist1</th><th>dist2</th><th>P_emaildomain</th><th>R_emaildomain</th><th>C1</th><th>C2</th><th>C3</th><th>C4</th><th>C5</th><th>C6</th><th>C7</th><th>C8</th><th>C9</th><th>C10</th><th>C11</th><th>C12</th><th>C13</th><th>C14</th><th>D1</th><th>D2</th><th>D3</th><th>D4</th><th>D5</th><th>D6</th><th>&hellip;</th><th>V303</th><th>V304</th><th>V305</th><th>V306</th><th>V307</th><th>V308</th><th>V309</th><th>V310</th><th>V311</th><th>V312</th><th>V313</th><th>V314</th><th>V315</th><th>V316</th><th>V317</th><th>V318</th><th>V319</th><th>V320</th><th>V321</th><th>V322</th><th>V323</th><th>V324</th><th>V325</th><th>V326</th><th>V327</th><th>V328</th><th>V329</th><th>V330</th><th>V331</th><th>V332</th><th>V333</th><th>V334</th><th>V335</th><th>V336</th><th>V337</th><th>V338</th><th>V339</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2987000</td><td>0</td><td>86400</td><td>68.5</td><td>&quot;W&quot;</td><td>13926</td><td>null</td><td>150.0</td><td>&quot;discover&quot;</td><td>142.0</td><td>&quot;credit&quot;</td><td>315.0</td><td>87.0</td><td>19.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>14.0</td><td>null</td><td>13.0</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>117.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>117.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2987001</td><td>0</td><td>86401</td><td>29.0</td><td>&quot;W&quot;</td><td>2755</td><td>404.0</td><td>150.0</td><td>&quot;mastercard&quot;</td><td>102.0</td><td>&quot;credit&quot;</td><td>325.0</td><td>87.0</td><td>null</td><td>null</td><td>&quot;gmail.com&quot;</td><td>null</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2987002</td><td>0</td><td>86469</td><td>59.0</td><td>&quot;W&quot;</td><td>4663</td><td>490.0</td><td>150.0</td><td>&quot;visa&quot;</td><td>166.0</td><td>&quot;debit&quot;</td><td>330.0</td><td>87.0</td><td>287.0</td><td>null</td><td>&quot;outlook.com&quot;</td><td>null</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2987003</td><td>0</td><td>86499</td><td>50.0</td><td>&quot;W&quot;</td><td>18132</td><td>567.0</td><td>150.0</td><td>&quot;mastercard&quot;</td><td>117.0</td><td>&quot;debit&quot;</td><td>476.0</td><td>87.0</td><td>null</td><td>null</td><td>&quot;yahoo.com&quot;</td><td>null</td><td>2.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>25.0</td><td>1.0</td><td>112.0</td><td>112.0</td><td>0.0</td><td>94.0</td><td>0.0</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>50.0</td><td>1758.0</td><td>925.0</td><td>0.0</td><td>354.0</td><td>0.0</td><td>135.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>50.0</td><td>1404.0</td><td>790.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2987004</td><td>0</td><td>86506</td><td>50.0</td><td>&quot;H&quot;</td><td>4497</td><td>514.0</td><td>150.0</td><td>&quot;mastercard&quot;</td><td>102.0</td><td>&quot;credit&quot;</td><td>420.0</td><td>87.0</td><td>null</td><td>null</td><td>&quot;gmail.com&quot;</td><td>null</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transaction.head() #isFraud adalah target featurenya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "2f60dc7d-73e8-4b8e-da13-3882a867e539",
        "id": "rAb9wA3jAYnn"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 393)\n",
              "┌───────────────┬───────────────┬────────────────┬───────────┬───┬──────┬──────┬──────┬──────┐\n",
              "│ TransactionID ┆ TransactionDT ┆ TransactionAmt ┆ ProductCD ┆ … ┆ V336 ┆ V337 ┆ V338 ┆ V339 │\n",
              "│ ---           ┆ ---           ┆ ---            ┆ ---       ┆   ┆ ---  ┆ ---  ┆ ---  ┆ ---  │\n",
              "│ i64           ┆ i64           ┆ f64            ┆ str       ┆   ┆ f64  ┆ f64  ┆ f64  ┆ f64  │\n",
              "╞═══════════════╪═══════════════╪════════════════╪═══════════╪═══╪══════╪══════╪══════╪══════╡\n",
              "│ 3663549       ┆ 18403224      ┆ 31.95          ┆ W         ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 3663550       ┆ 18403263      ┆ 49.0           ┆ W         ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 3663551       ┆ 18403310      ┆ 171.0          ┆ W         ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 3663552       ┆ 18403310      ┆ 284.95         ┆ W         ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "│ 3663553       ┆ 18403317      ┆ 67.95          ┆ W         ┆ … ┆ null ┆ null ┆ null ┆ null │\n",
              "└───────────────┴───────────────┴────────────────┴───────────┴───┴──────┴──────┴──────┴──────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 393)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>TransactionID</th><th>TransactionDT</th><th>TransactionAmt</th><th>ProductCD</th><th>card1</th><th>card2</th><th>card3</th><th>card4</th><th>card5</th><th>card6</th><th>addr1</th><th>addr2</th><th>dist1</th><th>dist2</th><th>P_emaildomain</th><th>R_emaildomain</th><th>C1</th><th>C2</th><th>C3</th><th>C4</th><th>C5</th><th>C6</th><th>C7</th><th>C8</th><th>C9</th><th>C10</th><th>C11</th><th>C12</th><th>C13</th><th>C14</th><th>D1</th><th>D2</th><th>D3</th><th>D4</th><th>D5</th><th>D6</th><th>D7</th><th>&hellip;</th><th>V303</th><th>V304</th><th>V305</th><th>V306</th><th>V307</th><th>V308</th><th>V309</th><th>V310</th><th>V311</th><th>V312</th><th>V313</th><th>V314</th><th>V315</th><th>V316</th><th>V317</th><th>V318</th><th>V319</th><th>V320</th><th>V321</th><th>V322</th><th>V323</th><th>V324</th><th>V325</th><th>V326</th><th>V327</th><th>V328</th><th>V329</th><th>V330</th><th>V331</th><th>V332</th><th>V333</th><th>V334</th><th>V335</th><th>V336</th><th>V337</th><th>V338</th><th>V339</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>3663549</td><td>18403224</td><td>31.95</td><td>&quot;W&quot;</td><td>10409</td><td>111.0</td><td>150.0</td><td>&quot;visa&quot;</td><td>226.0</td><td>&quot;debit&quot;</td><td>170.0</td><td>87.0</td><td>1.0</td><td>null</td><td>&quot;gmail.com&quot;</td><td>null</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>0.0</td><td>5.0</td><td>1.0</td><td>115.0</td><td>6.0</td><td>419.0</td><td>419.0</td><td>27.0</td><td>398.0</td><td>27.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>47.950001</td><td>0.0</td><td>0.0</td><td>47.950001</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3663550</td><td>18403263</td><td>49.0</td><td>&quot;W&quot;</td><td>4272</td><td>111.0</td><td>150.0</td><td>&quot;visa&quot;</td><td>226.0</td><td>&quot;debit&quot;</td><td>299.0</td><td>87.0</td><td>4.0</td><td>null</td><td>&quot;aol.com&quot;</td><td>null</td><td>3.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>12.0</td><td>2.0</td><td>149.0</td><td>149.0</td><td>7.0</td><td>634.0</td><td>7.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>280.0</td><td>77.0</td><td>0.0</td><td>280.0</td><td>0.0</td><td>77.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3663551</td><td>18403310</td><td>171.0</td><td>&quot;W&quot;</td><td>4476</td><td>574.0</td><td>150.0</td><td>&quot;visa&quot;</td><td>226.0</td><td>&quot;debit&quot;</td><td>472.0</td><td>87.0</td><td>2635.0</td><td>null</td><td>&quot;hotmail.com&quot;</td><td>null</td><td>2.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>22.0</td><td>2.0</td><td>137.0</td><td>137.0</td><td>10.0</td><td>97.0</td><td>10.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1321.0</td><td>0.0</td><td>0.0</td><td>1058.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>263.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3663552</td><td>18403310</td><td>284.95</td><td>&quot;W&quot;</td><td>10989</td><td>360.0</td><td>150.0</td><td>&quot;visa&quot;</td><td>166.0</td><td>&quot;debit&quot;</td><td>205.0</td><td>87.0</td><td>17.0</td><td>null</td><td>&quot;gmail.com&quot;</td><td>null</td><td>5.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>7.0</td><td>4.0</td><td>42.0</td><td>42.0</td><td>41.0</td><td>242.0</td><td>41.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>282.540009</td><td>282.540009</td><td>282.540009</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3663553</td><td>18403317</td><td>67.95</td><td>&quot;W&quot;</td><td>18018</td><td>452.0</td><td>150.0</td><td>&quot;mastercard&quot;</td><td>117.0</td><td>&quot;debit&quot;</td><td>264.0</td><td>87.0</td><td>6.0</td><td>null</td><td>&quot;gmail.com&quot;</td><td>null</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>6.0</td><td>0.0</td><td>14.0</td><td>6.0</td><td>22.0</td><td>22.0</td><td>0.0</td><td>22.0</td><td>0.0</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>67.949997</td><td>183.850006</td><td>67.949997</td><td>67.949997</td><td>183.850006</td><td>67.949997</td><td>67.949997</td><td>67.949997</td><td>183.850006</td><td>67.949997</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = train_transaction.null_count().transpose(include_header=True, column_names=[\"missing_count\"]).rename({'column': 'column_name'})\n",
        "missing_values = missing_values.with_columns(\n",
        "    (pl.col(\"missing_count\") / train_transaction.height * 100).alias(\"missing_percentage\")\n",
        ")\n",
        "\n",
        "print(missing_values.sort(\"missing_percentage\", descending=True))"
      ],
      "metadata": {
        "id": "45sdxczo8RuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a57490-a05a-4dad-b980-846bf51cab3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (394, 3)\n",
            "┌─────────────┬───────────────┬────────────────────┐\n",
            "│ column_name ┆ missing_count ┆ missing_percentage │\n",
            "│ ---         ┆ ---           ┆ ---                │\n",
            "│ str         ┆ u32           ┆ f64                │\n",
            "╞═════════════╪═══════════════╪════════════════════╡\n",
            "│ dist2       ┆ 552913        ┆ 93.628374          │\n",
            "│ D7          ┆ 551623        ┆ 93.40993           │\n",
            "│ D13         ┆ 528588        ┆ 89.509263          │\n",
            "│ D14         ┆ 528353        ┆ 89.469469          │\n",
            "│ D12         ┆ 525823        ┆ 89.041047          │\n",
            "│ …           ┆ …             ┆ …                  │\n",
            "│ C10         ┆ 0             ┆ 0.0                │\n",
            "│ C11         ┆ 0             ┆ 0.0                │\n",
            "│ C12         ┆ 0             ┆ 0.0                │\n",
            "│ C13         ┆ 0             ┆ 0.0                │\n",
            "│ C14         ┆ 0             ┆ 0.0                │\n",
            "└─────────────┴───────────────┴────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = test_transaction.null_count().transpose(include_header=True, column_names=[\"missing_count\"]).rename({'column': 'column_name'})\n",
        "missing_values = missing_values.with_columns(\n",
        "    (pl.col(\"missing_count\") / test_transaction.height * 100).alias(\"missing_percentage\")\n",
        ")\n",
        "\n",
        "print(missing_values.sort(\"missing_percentage\", descending=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414682bf-c3a7-4447-d7fd-99e874664c34",
        "id": "O1yCJOfKAeq_"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (393, 3)\n",
            "┌─────────────┬───────────────┬────────────────────┐\n",
            "│ column_name ┆ missing_count ┆ missing_percentage │\n",
            "│ ---         ┆ ---           ┆ ---                │\n",
            "│ str         ┆ u32           ┆ f64                │\n",
            "╞═════════════╪═══════════════╪════════════════════╡\n",
            "│ dist2       ┆ 470255        ┆ 92.80903           │\n",
            "│ D7          ┆ 446558        ┆ 88.132215          │\n",
            "│ D12         ┆ 437437        ┆ 86.332104          │\n",
            "│ D8          ┆ 432353        ┆ 85.328731          │\n",
            "│ D9          ┆ 432353        ┆ 85.328731          │\n",
            "│ …           ┆ …             ┆ …                  │\n",
            "│ V133        ┆ 0             ┆ 0.0                │\n",
            "│ V134        ┆ 0             ┆ 0.0                │\n",
            "│ V135        ┆ 0             ┆ 0.0                │\n",
            "│ V136        ┆ 0             ┆ 0.0                │\n",
            "│ V137        ┆ 0             ┆ 0.0                │\n",
            "└─────────────┴───────────────┴────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_transaction.schema)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a4VuwJHEVlv",
        "outputId": "7c96b839-1aac-4930-c315-4bf5ddb7c817"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema({'TransactionID': Int64, 'isFraud': Int64, 'TransactionDT': Int64, 'TransactionAmt': Float64, 'ProductCD': String, 'card1': Int64, 'card2': Float64, 'card3': Float64, 'card4': String, 'card5': Float64, 'card6': String, 'addr1': Float64, 'addr2': Float64, 'dist1': Float64, 'dist2': Float64, 'P_emaildomain': String, 'R_emaildomain': String, 'C1': Float64, 'C2': Float64, 'C3': Float64, 'C4': Float64, 'C5': Float64, 'C6': Float64, 'C7': Float64, 'C8': Float64, 'C9': Float64, 'C10': Float64, 'C11': Float64, 'C12': Float64, 'C13': Float64, 'C14': Float64, 'D1': Float64, 'D2': Float64, 'D3': Float64, 'D4': Float64, 'D5': Float64, 'D6': Float64, 'D7': Float64, 'D8': Float64, 'D9': Float64, 'D10': Float64, 'D11': Float64, 'D12': Float64, 'D13': Float64, 'D14': Float64, 'D15': Float64, 'M1': String, 'M2': String, 'M3': String, 'M4': String, 'M5': String, 'M6': String, 'M7': String, 'M8': String, 'M9': String, 'V1': Float64, 'V2': Float64, 'V3': Float64, 'V4': Float64, 'V5': Float64, 'V6': Float64, 'V7': Float64, 'V8': Float64, 'V9': Float64, 'V10': Float64, 'V11': Float64, 'V12': Float64, 'V13': Float64, 'V14': Float64, 'V15': Float64, 'V16': Float64, 'V17': Float64, 'V18': Float64, 'V19': Float64, 'V20': Float64, 'V21': Float64, 'V22': Float64, 'V23': Float64, 'V24': Float64, 'V25': Float64, 'V26': Float64, 'V27': Float64, 'V28': Float64, 'V29': Float64, 'V30': Float64, 'V31': Float64, 'V32': Float64, 'V33': Float64, 'V34': Float64, 'V35': Float64, 'V36': Float64, 'V37': Float64, 'V38': Float64, 'V39': Float64, 'V40': Float64, 'V41': Float64, 'V42': Float64, 'V43': Float64, 'V44': Float64, 'V45': Float64, 'V46': Float64, 'V47': Float64, 'V48': Float64, 'V49': Float64, 'V50': Float64, 'V51': Float64, 'V52': Float64, 'V53': Float64, 'V54': Float64, 'V55': Float64, 'V56': Float64, 'V57': Float64, 'V58': Float64, 'V59': Float64, 'V60': Float64, 'V61': Float64, 'V62': Float64, 'V63': Float64, 'V64': Float64, 'V65': Float64, 'V66': Float64, 'V67': Float64, 'V68': Float64, 'V69': Float64, 'V70': Float64, 'V71': Float64, 'V72': Float64, 'V73': Float64, 'V74': Float64, 'V75': Float64, 'V76': Float64, 'V77': Float64, 'V78': Float64, 'V79': Float64, 'V80': Float64, 'V81': Float64, 'V82': Float64, 'V83': Float64, 'V84': Float64, 'V85': Float64, 'V86': Float64, 'V87': Float64, 'V88': Float64, 'V89': Float64, 'V90': Float64, 'V91': Float64, 'V92': Float64, 'V93': Float64, 'V94': Float64, 'V95': Float64, 'V96': Float64, 'V97': Float64, 'V98': Float64, 'V99': Float64, 'V100': Float64, 'V101': Float64, 'V102': Float64, 'V103': Float64, 'V104': Float64, 'V105': Float64, 'V106': Float64, 'V107': Float64, 'V108': Float64, 'V109': Float64, 'V110': Float64, 'V111': Float64, 'V112': Float64, 'V113': Float64, 'V114': Float64, 'V115': Float64, 'V116': Float64, 'V117': Float64, 'V118': Float64, 'V119': Float64, 'V120': Float64, 'V121': Float64, 'V122': Float64, 'V123': Float64, 'V124': Float64, 'V125': Float64, 'V126': Float64, 'V127': Float64, 'V128': Float64, 'V129': Float64, 'V130': Float64, 'V131': Float64, 'V132': Float64, 'V133': Float64, 'V134': Float64, 'V135': Float64, 'V136': Float64, 'V137': Float64, 'V138': Float64, 'V139': Float64, 'V140': Float64, 'V141': Float64, 'V142': Float64, 'V143': Float64, 'V144': Float64, 'V145': Float64, 'V146': Float64, 'V147': Float64, 'V148': Float64, 'V149': Float64, 'V150': Float64, 'V151': Float64, 'V152': Float64, 'V153': Float64, 'V154': Float64, 'V155': Float64, 'V156': Float64, 'V157': Float64, 'V158': Float64, 'V159': Float64, 'V160': Float64, 'V161': Float64, 'V162': Float64, 'V163': Float64, 'V164': Float64, 'V165': Float64, 'V166': Float64, 'V167': Float64, 'V168': Float64, 'V169': Float64, 'V170': Float64, 'V171': Float64, 'V172': Float64, 'V173': Float64, 'V174': Float64, 'V175': Float64, 'V176': Float64, 'V177': Float64, 'V178': Float64, 'V179': Float64, 'V180': Float64, 'V181': Float64, 'V182': Float64, 'V183': Float64, 'V184': Float64, 'V185': Float64, 'V186': Float64, 'V187': Float64, 'V188': Float64, 'V189': Float64, 'V190': Float64, 'V191': Float64, 'V192': Float64, 'V193': Float64, 'V194': Float64, 'V195': Float64, 'V196': Float64, 'V197': Float64, 'V198': Float64, 'V199': Float64, 'V200': Float64, 'V201': Float64, 'V202': Float64, 'V203': Float64, 'V204': Float64, 'V205': Float64, 'V206': Float64, 'V207': Float64, 'V208': Float64, 'V209': Float64, 'V210': Float64, 'V211': Float64, 'V212': Float64, 'V213': Float64, 'V214': Float64, 'V215': Float64, 'V216': Float64, 'V217': Float64, 'V218': Float64, 'V219': Float64, 'V220': Float64, 'V221': Float64, 'V222': Float64, 'V223': Float64, 'V224': Float64, 'V225': Float64, 'V226': Float64, 'V227': Float64, 'V228': Float64, 'V229': Float64, 'V230': Float64, 'V231': Float64, 'V232': Float64, 'V233': Float64, 'V234': Float64, 'V235': Float64, 'V236': Float64, 'V237': Float64, 'V238': Float64, 'V239': Float64, 'V240': Float64, 'V241': Float64, 'V242': Float64, 'V243': Float64, 'V244': Float64, 'V245': Float64, 'V246': Float64, 'V247': Float64, 'V248': Float64, 'V249': Float64, 'V250': Float64, 'V251': Float64, 'V252': Float64, 'V253': Float64, 'V254': Float64, 'V255': Float64, 'V256': Float64, 'V257': Float64, 'V258': Float64, 'V259': Float64, 'V260': Float64, 'V261': Float64, 'V262': Float64, 'V263': Float64, 'V264': Float64, 'V265': Float64, 'V266': Float64, 'V267': Float64, 'V268': Float64, 'V269': Float64, 'V270': Float64, 'V271': Float64, 'V272': Float64, 'V273': Float64, 'V274': Float64, 'V275': Float64, 'V276': Float64, 'V277': Float64, 'V278': Float64, 'V279': Float64, 'V280': Float64, 'V281': Float64, 'V282': Float64, 'V283': Float64, 'V284': Float64, 'V285': Float64, 'V286': Float64, 'V287': Float64, 'V288': Float64, 'V289': Float64, 'V290': Float64, 'V291': Float64, 'V292': Float64, 'V293': Float64, 'V294': Float64, 'V295': Float64, 'V296': Float64, 'V297': Float64, 'V298': Float64, 'V299': Float64, 'V300': Float64, 'V301': Float64, 'V302': Float64, 'V303': Float64, 'V304': Float64, 'V305': Float64, 'V306': Float64, 'V307': Float64, 'V308': Float64, 'V309': Float64, 'V310': Float64, 'V311': Float64, 'V312': Float64, 'V313': Float64, 'V314': Float64, 'V315': Float64, 'V316': Float64, 'V317': Float64, 'V318': Float64, 'V319': Float64, 'V320': Float64, 'V321': Float64, 'V322': Float64, 'V323': Float64, 'V324': Float64, 'V325': Float64, 'V326': Float64, 'V327': Float64, 'V328': Float64, 'V329': Float64, 'V330': Float64, 'V331': Float64, 'V332': Float64, 'V333': Float64, 'V334': Float64, 'V335': Float64, 'V336': Float64, 'V337': Float64, 'V338': Float64, 'V339': Float64})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_transaction.schema)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6879d563-cb65-47e9-b15f-5de586cfe971",
        "id": "_jdWNKG3AnfH"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema({'TransactionID': Int64, 'TransactionDT': Int64, 'TransactionAmt': Float64, 'ProductCD': String, 'card1': Int64, 'card2': Float64, 'card3': Float64, 'card4': String, 'card5': Float64, 'card6': String, 'addr1': Float64, 'addr2': Float64, 'dist1': Float64, 'dist2': Float64, 'P_emaildomain': String, 'R_emaildomain': String, 'C1': Float64, 'C2': Float64, 'C3': Float64, 'C4': Float64, 'C5': Float64, 'C6': Float64, 'C7': Float64, 'C8': Float64, 'C9': Float64, 'C10': Float64, 'C11': Float64, 'C12': Float64, 'C13': Float64, 'C14': Float64, 'D1': Float64, 'D2': Float64, 'D3': Float64, 'D4': Float64, 'D5': Float64, 'D6': Float64, 'D7': Float64, 'D8': Float64, 'D9': Float64, 'D10': Float64, 'D11': Float64, 'D12': Float64, 'D13': Float64, 'D14': Float64, 'D15': Float64, 'M1': String, 'M2': String, 'M3': String, 'M4': String, 'M5': String, 'M6': String, 'M7': String, 'M8': String, 'M9': String, 'V1': Float64, 'V2': Float64, 'V3': Float64, 'V4': Float64, 'V5': Float64, 'V6': Float64, 'V7': Float64, 'V8': Float64, 'V9': Float64, 'V10': Float64, 'V11': Float64, 'V12': Float64, 'V13': Float64, 'V14': Float64, 'V15': Float64, 'V16': Float64, 'V17': Float64, 'V18': Float64, 'V19': Float64, 'V20': Float64, 'V21': Float64, 'V22': Float64, 'V23': Float64, 'V24': Float64, 'V25': Float64, 'V26': Float64, 'V27': Float64, 'V28': Float64, 'V29': Float64, 'V30': Float64, 'V31': Float64, 'V32': Float64, 'V33': Float64, 'V34': Float64, 'V35': Float64, 'V36': Float64, 'V37': Float64, 'V38': Float64, 'V39': Float64, 'V40': Float64, 'V41': Float64, 'V42': Float64, 'V43': Float64, 'V44': Float64, 'V45': Float64, 'V46': Float64, 'V47': Float64, 'V48': Float64, 'V49': Float64, 'V50': Float64, 'V51': Float64, 'V52': Float64, 'V53': Float64, 'V54': Float64, 'V55': Float64, 'V56': Float64, 'V57': Float64, 'V58': Float64, 'V59': Float64, 'V60': Float64, 'V61': Float64, 'V62': Float64, 'V63': Float64, 'V64': Float64, 'V65': Float64, 'V66': Float64, 'V67': Float64, 'V68': Float64, 'V69': Float64, 'V70': Float64, 'V71': Float64, 'V72': Float64, 'V73': Float64, 'V74': Float64, 'V75': Float64, 'V76': Float64, 'V77': Float64, 'V78': Float64, 'V79': Float64, 'V80': Float64, 'V81': Float64, 'V82': Float64, 'V83': Float64, 'V84': Float64, 'V85': Float64, 'V86': Float64, 'V87': Float64, 'V88': Float64, 'V89': Float64, 'V90': Float64, 'V91': Float64, 'V92': Float64, 'V93': Float64, 'V94': Float64, 'V95': Float64, 'V96': Float64, 'V97': Float64, 'V98': Float64, 'V99': Float64, 'V100': Float64, 'V101': Float64, 'V102': Float64, 'V103': Float64, 'V104': Float64, 'V105': Float64, 'V106': Float64, 'V107': Float64, 'V108': Float64, 'V109': Float64, 'V110': Float64, 'V111': Float64, 'V112': Float64, 'V113': Float64, 'V114': Float64, 'V115': Float64, 'V116': Float64, 'V117': Float64, 'V118': Float64, 'V119': Float64, 'V120': Float64, 'V121': Float64, 'V122': Float64, 'V123': Float64, 'V124': Float64, 'V125': Float64, 'V126': Float64, 'V127': Float64, 'V128': Float64, 'V129': Float64, 'V130': Float64, 'V131': Float64, 'V132': Float64, 'V133': Float64, 'V134': Float64, 'V135': Float64, 'V136': Float64, 'V137': Float64, 'V138': Float64, 'V139': Float64, 'V140': Float64, 'V141': Float64, 'V142': Float64, 'V143': Float64, 'V144': Float64, 'V145': Float64, 'V146': Float64, 'V147': Float64, 'V148': Float64, 'V149': Float64, 'V150': Float64, 'V151': Float64, 'V152': Float64, 'V153': Float64, 'V154': Float64, 'V155': Float64, 'V156': Float64, 'V157': Float64, 'V158': Float64, 'V159': Float64, 'V160': Float64, 'V161': Float64, 'V162': Float64, 'V163': Float64, 'V164': Float64, 'V165': Float64, 'V166': Float64, 'V167': Float64, 'V168': Float64, 'V169': Float64, 'V170': Float64, 'V171': Float64, 'V172': Float64, 'V173': Float64, 'V174': Float64, 'V175': Float64, 'V176': Float64, 'V177': Float64, 'V178': Float64, 'V179': Float64, 'V180': Float64, 'V181': Float64, 'V182': Float64, 'V183': Float64, 'V184': Float64, 'V185': Float64, 'V186': Float64, 'V187': Float64, 'V188': Float64, 'V189': Float64, 'V190': Float64, 'V191': Float64, 'V192': Float64, 'V193': Float64, 'V194': Float64, 'V195': Float64, 'V196': Float64, 'V197': Float64, 'V198': Float64, 'V199': Float64, 'V200': Float64, 'V201': Float64, 'V202': Float64, 'V203': Float64, 'V204': Float64, 'V205': Float64, 'V206': Float64, 'V207': Float64, 'V208': Float64, 'V209': Float64, 'V210': Float64, 'V211': Float64, 'V212': Float64, 'V213': Float64, 'V214': Float64, 'V215': Float64, 'V216': Float64, 'V217': Float64, 'V218': Float64, 'V219': Float64, 'V220': Float64, 'V221': Float64, 'V222': Float64, 'V223': Float64, 'V224': Float64, 'V225': Float64, 'V226': Float64, 'V227': Float64, 'V228': Float64, 'V229': Float64, 'V230': Float64, 'V231': Float64, 'V232': Float64, 'V233': Float64, 'V234': Float64, 'V235': Float64, 'V236': Float64, 'V237': Float64, 'V238': Float64, 'V239': Float64, 'V240': Float64, 'V241': Float64, 'V242': Float64, 'V243': Float64, 'V244': Float64, 'V245': Float64, 'V246': Float64, 'V247': Float64, 'V248': Float64, 'V249': Float64, 'V250': Float64, 'V251': Float64, 'V252': Float64, 'V253': Float64, 'V254': Float64, 'V255': Float64, 'V256': Float64, 'V257': Float64, 'V258': Float64, 'V259': Float64, 'V260': Float64, 'V261': Float64, 'V262': Float64, 'V263': Float64, 'V264': Float64, 'V265': Float64, 'V266': Float64, 'V267': Float64, 'V268': Float64, 'V269': Float64, 'V270': Float64, 'V271': Float64, 'V272': Float64, 'V273': Float64, 'V274': Float64, 'V275': Float64, 'V276': Float64, 'V277': Float64, 'V278': Float64, 'V279': Float64, 'V280': Float64, 'V281': Float64, 'V282': Float64, 'V283': Float64, 'V284': Float64, 'V285': Float64, 'V286': Float64, 'V287': Float64, 'V288': Float64, 'V289': Float64, 'V290': Float64, 'V291': Float64, 'V292': Float64, 'V293': Float64, 'V294': Float64, 'V295': Float64, 'V296': Float64, 'V297': Float64, 'V298': Float64, 'V299': Float64, 'V300': Float64, 'V301': Float64, 'V302': Float64, 'V303': Float64, 'V304': Float64, 'V305': Float64, 'V306': Float64, 'V307': Float64, 'V308': Float64, 'V309': Float64, 'V310': Float64, 'V311': Float64, 'V312': Float64, 'V313': Float64, 'V314': Float64, 'V315': Float64, 'V316': Float64, 'V317': Float64, 'V318': Float64, 'V319': Float64, 'V320': Float64, 'V321': Float64, 'V322': Float64, 'V323': Float64, 'V324': Float64, 'V325': Float64, 'V326': Float64, 'V327': Float64, 'V328': Float64, 'V329': Float64, 'V330': Float64, 'V331': Float64, 'V332': Float64, 'V333': Float64, 'V334': Float64, 'V335': Float64, 'V336': Float64, 'V337': Float64, 'V338': Float64, 'V339': Float64})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = missing_values.filter(pl.col(\"missing_percentage\") > 90.0).select(\"column_name\").to_series().to_list()"
      ],
      "metadata": {
        "id": "Ok_AteMeEjOv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transaction = train_transaction.drop(columns_to_drop)\n",
        "\n",
        "print(f\"New shape of train_transaction after dropping columns: {train_transaction.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up5Qu_yZEo8a",
        "outputId": "dfa96ff0-2104-4437-e9ee-fdef18659520"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train_transaction after dropping columns: (590540, 393)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transaction = test_transaction.drop(columns_to_drop)\n",
        "\n",
        "print(f\"New shape of train_transaction after dropping columns: {train_transaction.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d73437-d365-421c-bc59-07276c398c1c",
        "id": "DqgtbjOKAwmP"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train_transaction after dropping columns: (590540, 393)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = []\n",
        "for column_name, dtype in train_transaction.schema.items():\n",
        "    if str(dtype) == 'Int64' or str(dtype) == 'Float64':\n",
        "        numerical_columns.append(column_name)\n",
        "\n",
        "print(f\"Identified numerical columns: {numerical_columns}\")\n",
        "print(f\"Number of numerical columns: {len(numerical_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ycNPxgExBx",
        "outputId": "f84ed38b-68c0-4734-ea9b-9e1625d07c45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified numerical columns: ['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt', 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']\n",
            "Number of numerical columns: 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = []\n",
        "for column_name, dtype in test_transaction.schema.items():\n",
        "    if str(dtype) == 'Int64' or str(dtype) == 'Float64':\n",
        "        numerical_columns.append(column_name)\n",
        "\n",
        "print(f\"Identified numerical columns: {numerical_columns}\")\n",
        "print(f\"Number of numerical columns: {len(numerical_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d72a10-12ff-406c-cade-e6e7eea14996",
        "id": "qo5jvporA20v"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified numerical columns: ['TransactionID', 'TransactionDT', 'TransactionAmt', 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']\n",
            "Number of numerical columns: 378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Filter numerical_columns to exclude 'isFraud' (target) and 'TransactionID' (identifier) for features\n",
        "feature_columns = [col for col in numerical_columns if col not in ['isFraud', 'TransactionID']]\n",
        "X = train_transaction.select(feature_columns)\n",
        "y = train_transaction['isFraud']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgfXXOoRE905",
        "outputId": "35435239-9072-46e9-d295-fade771d9bae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (413378, 377)\n",
            "Shape of X_test: (177162, 377)\n",
            "Shape of y_train: (413378,)\n",
            "Shape of y_test: (177162,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Get the target variable values\n",
        "y_true = train_transaction['isFraud'].to_numpy()\n",
        "\n",
        "# Calculate class weights\n",
        "classes = np.unique(y_true)\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_true)\n",
        "\n",
        "# Create a dictionary for easier access\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "print(f\"Calculated Class Weights: {class_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jApW9eRMFLRV",
        "outputId": "787f0574-f776-411d-ac56-4b4ee539b8e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated Class Weights: {np.int64(0): np.float64(0.5181293507195412), np.int64(1): np.float64(14.289793350433142)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_columns:\n",
        "    if train_transaction[col].null_count() > 0:\n",
        "        median_val = train_transaction[col].median()\n",
        "        train_transaction = train_transaction.with_columns(pl.col(col).fill_null(median_val))\n",
        "print(\"Missing values in numerical columns after imputation:\")\n",
        "print(train_transaction[numerical_columns].null_count().sum().to_series())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT1I6LeaFXUl",
        "outputId": "524aa6d9-14b2-4298-f875-01afa74bb2d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in numerical columns after imputation:\n",
            "shape: (1,)\n",
            "Series: 'TransactionID' [u32]\n",
            "[\n",
            "\t0\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def build_advanced_tabular_model(input_dim):\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # ------- Dense block 1 -------\n",
        "    x = layers.Dense(256, activation='gelu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-5))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # ------- Dense block 2 (Residual) -------\n",
        "    skip = x\n",
        "    x = layers.Dense(256, activation='gelu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-5))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.Add()([x, skip])   # Residual connection\n",
        "\n",
        "    # ------- Dense block 3 -------\n",
        "    x = layers.Dense(128, activation='gelu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-5))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # ------- Dense block 4 -------\n",
        "    x = layers.Dense(64, activation='gelu')(x)\n",
        "    x = layers.Dropout(0.15)(x)\n",
        "\n",
        "    # ------- Output -------\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Build\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    # Compile with AdamW (better than Adam)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = build_advanced_tabular_model(X_train.shape[1])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "qqAdrc25GUcn",
        "outputId": "a6f8a02b-41cb-4a0b-9d5f-3d98944bcb94"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m377\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m96,768\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">377</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">96,768</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,337\u001b[0m (806.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,337</span> (806.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,057\u001b[0m (801.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,057</span> (801.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model compiled successfully with Adam optimizer, binary cross-entropy loss, and accuracy metric.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8F9xoATGaQu",
        "outputId": "e3aaca69-4add-42ac-c0e4-cf96826998de"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled successfully with Adam optimizer, binary cross-entropy loss, and accuracy metric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "print(\"Deep learning model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzBqu18FGjsr",
        "outputId": "edc90d01-789a-4c3d-eb99-2f612f449c4a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 2/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 3/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 4/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 5/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 6/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 7/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 8/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 9/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 10/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 11/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 12ms/step - accuracy: 0.9653 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 12/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 13/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 14/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 15/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 16/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 17/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 18/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 13ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 19/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 20/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 21/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 22/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 23/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 24/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 25/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 26/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 27/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 28/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 29/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 30/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 31/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 32/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9641 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 33/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9653 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 34/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 35/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 36/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 37/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 38/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 39/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 40/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 41/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 42/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 43/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 44/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9653 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 45/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 46/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 47/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 13ms/step - accuracy: 0.9653 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 48/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 49/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 50/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 14ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 51/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 52/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 53/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 54/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 55/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 56/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 57/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 58/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 59/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9641 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 60/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 61/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 62/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 63/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 64/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 65/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 66/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 67/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 68/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 69/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 70/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 71/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 72/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 73/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 74/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 12ms/step - accuracy: 0.9651 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 75/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 76/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 77/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9642 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 78/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 79/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 12ms/step - accuracy: 0.9646 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 80/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9642 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 81/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 82/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 83/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 84/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 85/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 86/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 87/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 88/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 89/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 90/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 91/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 92/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 93/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 94/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 95/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 96/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 97/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 98/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 99/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Epoch 100/100\n",
            "\u001b[1m5168/5168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: nan - val_accuracy: 0.9659 - val_loss: nan\n",
            "Deep learning model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c6185f",
        "outputId": "c3787014-addb-4383-9160-5abb6faa4f11"
      },
      "source": [
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred_classes = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"Predicted probabilities (first 5):\")\n",
        "print(y_pred_proba[:5])\n",
        "print(\"Predicted binary classes (first 5):\")\n",
        "print(y_pred_classes[:5])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5537/5537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
            "Predicted probabilities (first 5):\n",
            "[[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "Predicted binary classes (first 5):\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d45571b",
        "outputId": "6b76620e-a9e7-4749-8169-2ec484f8ecad"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_pred_classes))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98    170963\n",
            "           1       0.00      0.00      0.00      6199\n",
            "\n",
            "    accuracy                           0.97    177162\n",
            "   macro avg       0.48      0.50      0.49    177162\n",
            "weighted avg       0.93      0.97      0.95    177162\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "2e36ccb2",
        "outputId": "cef61b15-bf5c-4e9c-ab4e-db0334cd8a57"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "print(\"Plotted training and validation loss and accuracy.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotted training and validation loss and accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96c72a4a"
      },
      "source": [
        "# Task\n",
        "Train a RandomForestClassifier model with balanced class weights using the preprocessed `X_train` and `y_train` data, then evaluate its performance on the `X_test` and `y_test` data by generating a classification report, and finally compare these results with the previously obtained deep learning model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "370b33c9"
      },
      "source": [
        "## Train RandomForestClassifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize a RandomForestClassifier with class_weight='balanced', then train it using the X_train and y_train datasets. Convert Polars DataFrames to NumPy arrays for scikit-learn compatibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ab9df9e"
      },
      "source": [
        "**Reasoning**:\n",
        "To train a RandomForestClassifier, I need to first import the class, initialize the model with specified parameters, convert the Polars DataFrames to NumPy arrays for compatibility with scikit-learn, and then fit the model to the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ce1a6e",
        "outputId": "c6d9907d-3a23-47ab-b840-0df5651ec529"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Convert Polars DataFrames to NumPy arrays\n",
        "X_train_np = X_train.to_numpy()\n",
        "y_train_np = y_train.to_numpy()\n",
        "\n",
        "# Initialize RandomForestClassifier with class_weight='balanced'\n",
        "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_np, y_train_np)\n",
        "\n",
        "print(\"RandomForestClassifier initialized and trained successfully.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier initialized and trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f308c39b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because 'X_train' was not defined, indicating that the data splitting and preprocessing steps were not executed or were executed incorrectly. Additionally, the deep learning model training resulted in 'loss: nan', suggesting that missing values were present in the training data. This fix consolidates the necessary data preparation steps—identifying numerical columns, imputing missing values, splitting the data into training and test sets, and calculating class weights—in the correct order before any model training, ensuring `X_train` and `y_train` are properly defined and cleaned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36d71671",
        "outputId": "b540ff73-c733-4954-9bb5-191497917d05"
      },
      "source": [
        "import polars as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Ensure `train_transaction` is in the state after column dropping\n",
        "# (Assuming `train_transaction` and `columns_to_drop` are available from previous successful executions)\n",
        "\n",
        "# 1. Identify numerical columns from the (potentially updated) train_transaction schema\n",
        "numerical_cols_train = []\n",
        "for column_name, dtype in train_transaction.schema.items():\n",
        "    if str(dtype) in ['Int64', 'Float64']:\n",
        "        numerical_cols_train.append(column_name)\n",
        "\n",
        "# Remove 'isFraud' and 'TransactionID' from the list of columns to be imputed/features if present\n",
        "feature_cols_for_imputation = [col for col in numerical_cols_train if col not in ['isFraud', 'TransactionID']]\n",
        "\n",
        "# 2. Impute missing values in numerical columns of train_transaction BEFORE splitting\n",
        "print(\"Imputing missing values in numerical feature columns of train_transaction...\")\n",
        "for col in feature_cols_for_imputation:\n",
        "    if train_transaction[col].null_count() > 0:\n",
        "        median_val = train_transaction[col].median()\n",
        "        train_transaction = train_transaction.with_columns(pl.col(col).fill_null(median_val))\n",
        "print(\"Missing values imputed.\")\n",
        "\n",
        "# Verify no missing numerical values in feature columns after imputation\n",
        "print(\"Missing values in feature columns of train_transaction after imputation:\")\n",
        "print(train_transaction.select(feature_cols_for_imputation).null_count().sum().to_series())\n",
        "\n",
        "\n",
        "# 3. Define features (X) and target (y)\n",
        "X = train_transaction.select(feature_cols_for_imputation)\n",
        "y = train_transaction['isFraud']\n",
        "\n",
        "# 4. Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "# 5. Calculate class weights for the full training target (y_true from train_transaction)\n",
        "y_true_full = train_transaction['isFraud'].to_numpy()\n",
        "classes = np.unique(y_true_full)\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_true_full)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "print(f\"Calculated Class Weights: {class_weights}\")\n",
        "\n",
        "print(\"Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing missing values in numerical feature columns of train_transaction...\n",
            "Missing values imputed.\n",
            "Missing values in feature columns of train_transaction after imputation:\n",
            "shape: (1,)\n",
            "Series: 'TransactionDT' [u32]\n",
            "[\n",
            "\t0\n",
            "]\n",
            "Shape of X_train: (413378, 377)\n",
            "Shape of X_test: (177162, 377)\n",
            "Shape of y_train: (413378,)\n",
            "Shape of y_test: (177162,)\n",
            "Calculated Class Weights: {np.int64(0): np.float64(0.5181293507195412), np.int64(1): np.float64(14.289793350433142)}\n",
            "Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cd26046"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because 'train_transaction' was not defined, likely due to a kernel reset or cells not being executed in order. This fix re-loads the 'train_transaction' dataset, re-applies the column dropping based on missing values, and then proceeds with identifying numerical features, imputing missing values, splitting the data, and calculating class weights. This ensures all necessary data preparation steps are completed sequentially within a single block, making `X_train`, `y_train`, `X_test`, `y_test`, and `class_weights` correctly defined and cleaned for subsequent model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef4ce94f",
        "outputId": "500267d9-ba1a-4a07-8ad6-6d54017b489b"
      },
      "source": [
        "import polars as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "BASE_PATH = \"midterm_folder\"\n",
        "\n",
        "# 1. Re-load train_transaction to ensure it's defined\n",
        "train_transaction = pl.read_csv(f\"{BASE_PATH}/train_transaction.csv\")\n",
        "\n",
        "# 2. Re-calculate columns_to_drop based on missing values > 90% (as per original logic)\n",
        "missing_values = train_transaction.null_count().transpose(include_header=True, column_names=[\"missing_count\"]).rename({'column': 'column_name'})\n",
        "missing_values = missing_values.with_columns(\n",
        "    (pl.col(\"missing_count\") / train_transaction.height * 100).alias(\"missing_percentage\")\n",
        ")\n",
        "columns_to_drop = missing_values.filter(pl.col(\"missing_percentage\") > 90.0).select(\"column_name\").to_series().to_list()\n",
        "\n",
        "# 3. Drop identified columns\n",
        "train_transaction = train_transaction.drop(columns_to_drop)\n",
        "print(f\"Shape of train_transaction after dropping columns: {train_transaction.shape}\")\n",
        "\n",
        "# 4. Identify numerical columns from the (updated) train_transaction schema\n",
        "numerical_cols_train = []\n",
        "for column_name, dtype in train_transaction.schema.items():\n",
        "    if str(dtype) in ['Int64', 'Float64']:\n",
        "        numerical_cols_train.append(column_name)\n",
        "\n",
        "# Remove 'isFraud' and 'TransactionID' from the list of columns to be imputed/features\n",
        "feature_cols_for_imputation = [col for col in numerical_cols_train if col not in ['isFraud', 'TransactionID']]\n",
        "\n",
        "# 5. Impute missing values in numerical columns of train_transaction BEFORE splitting\n",
        "print(\"Imputing missing values in numerical feature columns of train_transaction...\")\n",
        "for col in feature_cols_for_imputation:\n",
        "    if train_transaction[col].null_count() > 0:\n",
        "        median_val = train_transaction[col].median()\n",
        "        train_transaction = train_transaction.with_columns(pl.col(col).fill_null(median_val))\n",
        "print(\"Missing values imputed.\")\n",
        "\n",
        "# Verify no missing numerical values in feature columns after imputation\n",
        "print(\"Missing values in feature columns of train_transaction after imputation:\")\n",
        "print(train_transaction.select(feature_cols_for_imputation).null_count().sum().to_series())\n",
        "\n",
        "\n",
        "# 6. Define features (X) and target (y)\n",
        "X = train_transaction.select(feature_cols_for_imputation)\n",
        "y = train_transaction['isFraud']\n",
        "\n",
        "# 7. Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "# 8. Calculate class weights for the full training target (y_true from train_transaction)\n",
        "y_true_full = train_transaction['isFraud'].to_numpy()\n",
        "classes = np.unique(y_true_full)\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_true_full)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "print(f\"Calculated Class Weights: {class_weights}\")\n",
        "\n",
        "print(\"Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_transaction after dropping columns: (590540, 392)\n",
            "Imputing missing values in numerical feature columns of train_transaction...\n",
            "Missing values imputed.\n",
            "Missing values in feature columns of train_transaction after imputation:\n",
            "shape: (1,)\n",
            "Series: 'TransactionDT' [u32]\n",
            "[\n",
            "\t0\n",
            "]\n",
            "Shape of X_train: (413378, 376)\n",
            "Shape of X_test: (177162, 376)\n",
            "Shape of y_train: (413378,)\n",
            "Shape of y_test: (177162,)\n",
            "Calculated Class Weights: {np.int64(0): np.float64(0.5181293507195412), np.int64(1): np.float64(14.289793350433142)}\n",
            "Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7646d62a"
      },
      "source": [
        "**Reasoning**:\n",
        "The `FileNotFoundError` indicates that the `midterm_folder/train_transaction.csv` file is missing. This suggests that the initial file download command might not have been executed or completed successfully. I need to re-execute the file download to ensure the data is present in the expected directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aaf58a1",
        "outputId": "2dd1bd6a-c4ca-4080-d8bc-63cf6a2f4adb"
      },
      "source": [
        "!pip install -q gdown\n",
        "!gdown --folder 13855F-3guh83abqSUm_ffmrQcb5-5TUM -O midterm_folder"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7 test_transaction.csv\n",
            "Processing file 1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_ train_transaction.csv\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7\n",
            "From (redirected): https://drive.google.com/uc?id=1ulFJG9NeSYLkttO4lYdYCB1a08cRtnx7&confirm=t&uuid=523dfe66-e58c-4557-b82f-4f868cd11a3c\n",
            "To: /content/midterm_folder/test_transaction.csv\n",
            "100% 613M/613M [00:09<00:00, 62.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_\n",
            "From (redirected): https://drive.google.com/uc?id=1IY7hP2X7LgFXC3IRqkqDRT_-a0sTv0h_&confirm=t&uuid=2e954810-86de-4ce5-8897-9ec074b5300e\n",
            "To: /content/midterm_folder/train_transaction.csv\n",
            "100% 683M/683M [00:09<00:00, 69.0MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eb005dd"
      },
      "source": [
        "**Reasoning**:\n",
        "The data files are now confirmed to be downloaded. I need to re-execute the comprehensive data preparation block that re-loads the data, drops columns with high missing values, imputes numerical missing values, splits the data, and calculates class weights. This will ensure that `X_train`, `y_train`, `X_test`, `y_test`, and `class_weights` are correctly defined and ready for model training, addressing all previous `NameError` and `FileNotFoundError` issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dfb0bc1",
        "outputId": "d8c70b12-a7ff-4559-a2fb-672bed4a34f4"
      },
      "source": [
        "import polars as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "BASE_PATH = \"midterm_folder\"\n",
        "\n",
        "# 1. Re-load train_transaction to ensure it's defined\n",
        "train_transaction = pl.read_csv(f\"{BASE_PATH}/train_transaction.csv\")\n",
        "\n",
        "# 2. Re-calculate columns_to_drop based on missing values > 90% (as per original logic)\n",
        "missing_values = train_transaction.null_count().transpose(include_header=True, column_names=[\"missing_count\"]).rename({'column': 'column_name'})\n",
        "missing_values = missing_values.with_columns(\n",
        "    (pl.col(\"missing_count\") / train_transaction.height * 100).alias(\"missing_percentage\")\n",
        ")\n",
        "columns_to_drop = missing_values.filter(pl.col(\"missing_percentage\") > 90.0).select(\"column_name\").to_series().to_list()\n",
        "\n",
        "# 3. Drop identified columns\n",
        "train_transaction = train_transaction.drop(columns_to_drop)\n",
        "print(f\"Shape of train_transaction after dropping columns: {train_transaction.shape}\")\n",
        "\n",
        "# 4. Identify numerical columns from the (updated) train_transaction schema\n",
        "numerical_cols_train = []\n",
        "for column_name, dtype in train_transaction.schema.items():\n",
        "    if str(dtype) in ['Int64', 'Float64']:\n",
        "        numerical_cols_train.append(column_name)\n",
        "\n",
        "# Remove 'isFraud' and 'TransactionID' from the list of columns to be imputed/features\n",
        "feature_cols_for_imputation = [col for col in numerical_cols_train if col not in ['isFraud', 'TransactionID']]\n",
        "\n",
        "# 5. Impute missing values in numerical columns of train_transaction BEFORE splitting\n",
        "print(\"Imputing missing values in numerical feature columns of train_transaction...\")\n",
        "for col in feature_cols_for_imputation:\n",
        "    if train_transaction[col].null_count() > 0:\n",
        "        median_val = train_transaction[col].median()\n",
        "        train_transaction = train_transaction.with_columns(pl.col(col).fill_null(median_val))\n",
        "print(\"Missing values imputed.\")\n",
        "\n",
        "# Verify no missing numerical values in feature columns after imputation\n",
        "print(\"Missing values in feature columns of train_transaction after imputation:\")\n",
        "print(train_transaction.select(feature_cols_for_imputation).null_count().sum().to_series())\n",
        "\n",
        "\n",
        "# 6. Define features (X) and target (y)\n",
        "X = train_transaction.select(feature_cols_for_imputation)\n",
        "y = train_transaction['isFraud']\n",
        "\n",
        "# 7. Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "# 8. Calculate class weights for the full training target (y_true from train_transaction)\n",
        "y_true_full = train_transaction['isFraud'].to_numpy()\n",
        "classes = np.unique(y_true_full)\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_true_full)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "print(f\"Calculated Class Weights: {class_weights}\")\n",
        "\n",
        "print(\"Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_transaction after dropping columns: (590540, 392)\n",
            "Imputing missing values in numerical feature columns of train_transaction...\n",
            "Missing values imputed.\n",
            "Missing values in feature columns of train_transaction after imputation:\n",
            "shape: (1,)\n",
            "Series: 'TransactionDT' [u32]\n",
            "[\n",
            "\t0\n",
            "]\n",
            "Shape of X_train: (413378, 376)\n",
            "Shape of X_test: (177162, 376)\n",
            "Shape of y_train: (413378,)\n",
            "Shape of y_test: (177162,)\n",
            "Calculated Class Weights: {np.int64(0): np.float64(0.5181293507195412), np.int64(1): np.float64(14.289793350433142)}\n",
            "Data preparation complete: X_train, y_train, X_test, y_test, and class_weights are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b816630d"
      },
      "source": [
        "**Reasoning**:\n",
        "The data preparation step was successfully completed in the previous execution, ensuring that `X_train`, `y_train`, `X_test`, `y_test`, and `class_weights` are now properly defined. Therefore, I will re-execute the code block to initialize and train the RandomForestClassifier model, converting the Polars DataFrames to NumPy arrays as required by scikit-learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4461f1c8",
        "outputId": "fad5c867-4334-48b0-eedf-156ae67052c7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Convert Polars DataFrames to NumPy arrays\n",
        "X_train_np = X_train.to_numpy()\n",
        "y_train_np = y_train.to_numpy()\n",
        "\n",
        "# Initialize RandomForestClassifier with class_weight='balanced'\n",
        "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_np, y_train_np)\n",
        "\n",
        "print(\"RandomForestClassifier initialized and trained successfully.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier initialized and trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ac6403a"
      },
      "source": [
        "## Predict and Evaluate RandomForest\n",
        "\n",
        "### Subtask:\n",
        "Make predictions on X_test using the trained RandomForestClassifier and generate a classification report to assess its performance. The report will include precision, recall, and f1-score for both classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ec63b85"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to make predictions using the trained RandomForestClassifier on the X_test data, convert X_test and y_test to NumPy arrays, and then generate a classification report to evaluate the model's performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78a1e3b4",
        "outputId": "e9271c04-c8c3-4a98-f0a3-d1f834430fb3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert X_test (Polars DataFrame) to a NumPy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Convert y_test (Polars Series) to a NumPy array\n",
        "y_test_np = y_test.to_numpy()\n",
        "\n",
        "# Make predictions on X_test using the trained RandomForestClassifier\n",
        "y_pred_rf = rf_model.predict(X_test_np)\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(\"Classification Report for RandomForestClassifier on Test Set:\")\n",
        "print(classification_report(y_test_np, y_pred_rf))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for RandomForestClassifier on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    170963\n",
            "           1       0.92      0.40      0.55      6199\n",
            "\n",
            "    accuracy                           0.98    177162\n",
            "   macro avg       0.95      0.70      0.77    177162\n",
            "weighted avg       0.98      0.98      0.97    177162\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "092e6937"
      },
      "source": [
        "## Summarize and Compare Models\n",
        "\n",
        "### Subtask:\n",
        "Summarize the performance of the RandomForestClassifier based on the classification report. Compare these results with the previously observed performance of the deep learning model, particularly focusing on how well each model handles the minority (fraudulent) class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cf77e89"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The RandomForestClassifier model achieved an overall accuracy of 0.98. For the minority (fraudulent) class, it demonstrated a precision of 0.92, a recall of 0.40, and an F1-score of 0.55. A direct comparison with the deep learning model's performance could not be performed as the deep learning model's metrics were not provided in the current solving process.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The RandomForestClassifier model, trained with balanced class weights, achieved a high overall accuracy of 0.98 on the test set.\n",
        "*   For the majority (non-fraudulent) class (Class 0), the model performed exceptionally well with precision, recall, and F1-score all at 0.98 or higher (0.98 precision, 1.00 recall, 0.99 F1-score).\n",
        "*   For the minority (fraudulent) class (Class 1), the model showed strong precision at 0.92, indicating that when it predicts fraud, it is often correct. However, its recall for this class was notably lower at 0.40, meaning it only identified 40% of the actual fraudulent transactions. The F1-score for this class was 0.55.\n",
        "*   The significant difference between precision (0.92) and recall (0.40) for the fraudulent class suggests the model is good at avoiding false positives but struggles to identify all true fraudulent cases.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   To fully address the task, the performance metrics of the deep learning model, especially its recall for the fraudulent class, should be retrieved to enable a direct and comprehensive comparison with the RandomForestClassifier.\n",
        "*   Investigate techniques to further improve the recall for the minority (fraudulent) class in the RandomForestClassifier, such as exploring different sampling methods (e.g., SMOTE) or adjusting the classification threshold, given that missing fraudulent transactions (low recall) can be more costly than false positives.\n"
      ]
    }
  ]
}